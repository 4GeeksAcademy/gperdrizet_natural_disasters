{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-16 00:46:50.400088: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-01-16 00:46:50.403019: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-01-16 00:46:50.410585: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1736988410.425217   26110 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1736988410.429466   26110 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-01-16 00:46:50.445930: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime as dt\n",
    "import tensorflow as tf\n",
    "import urllib.request, json\n",
    "import os\n",
    "\n",
    "from math import sqrt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from pandas_datareader import data\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.preprocessing import FunctionTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop irrelevant columns\n",
    "columns_to_drop = [\n",
    "    \"fema_declaration_string\", \"fips\", \"place_code\", \"hash\", \"id\", \"last_refresh\", \n",
    "    \"last_ia_filing_date\", \"fy_declared\", \"ih_program_declared\", \"ia_program_declared\", \n",
    "    \"declaration_type\", \"pa_program_declared\", \"hm_program_declared\", \n",
    "    \"disaster_closeout_date\", \"declaration_request_number\"\n",
    "]\n",
    "df.drop(columns=columns_to_drop, inplace=True, errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert date column to datetime and sort\n",
    "df['incident_begin_date'] = pd.to_datetime(df['incident_begin_date'])\n",
    "df.sort_values('incident_begin_date', inplace=True)\n",
    "\n",
    "# Select 3 most common disaster types\n",
    "top_disasters=df['incident_type'].value_counts().head(3).index\n",
    "df['top_disasters']=df['incident_type'].apply(lambda x: 1 if x in top_disasters else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create 'year' column to filter year from 'incident_dtm'\n",
    "df['year']=pd.to_datetime(df['incident_begin_date'], format='%Y').dt.year\n",
    "\n",
    "# Drop years before 2013\n",
    "df=df[df['year'] >= 2013]\n",
    "\n",
    "# Aggregate monthly disaster counts\n",
    "df['month']=df['incident_begin_date'].dt.to_period('M')\n",
    "monthly_disasters=df.groupby('month')['top_disasters'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame with features\n",
    "monthly_features=pd.DataFrame({'month': monthly_disasters.index.to_timestamp(), 'disaster_count': monthly_disasters.values})\n",
    "\n",
    "# Create lagged features\n",
    "monthly_features['lag_1']=monthly_features['disaster_count'].shift(1)\n",
    "monthly_features['lag_2']=monthly_features['disaster_count'].shift(2)\n",
    "monthly_features['lag_3']=monthly_features['disaster_count'].shift(3)\n",
    "\n",
    "# Add a binary for disaster occurrence\n",
    "monthly_features['disaster?']=monthly_features['disaster_count'].apply(lambda x: 1 if x > 0 else 0)\n",
    "\n",
    "# Drop rows with NaN values created by lagging\n",
    "monthly_features.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features and target variable\n",
    "X = monthly_features[['lag_1', 'lag_2', 'lag_3']]\n",
    "y = monthly_features['disaster?']\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, shuffle=False)\n",
    "\n",
    "print(f\"Training data shape: {X_train.shape}, Testing data shape: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define transformers for sine and cosine\n",
    "def sin_transformer(period):\n",
    "    return FunctionTransformer(lambda x: np.sin(x / period * 2 * np.pi))\n",
    "\n",
    "def cos_transformer(period):\n",
    "    return FunctionTransformer(lambda x: np.cos(x / period * 2 * np.pi))\n",
    "\n",
    "# Add 'month_int' column to represent months as integers\n",
    "monthly_features['month_int'] = monthly_features['month'].dt.month\n",
    "\n",
    "# Apply sine and cosine transformations\n",
    "monthly_features['month_sin'] = sin_transformer(12).fit_transform(monthly_features[['month_int']])\n",
    "monthly_features['month_cos'] = cos_transformer(12).fit_transform(monthly_features[['month_int']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a one-hot encoded DataFrame for the 'state' column\n",
    "state_dummies = pd.get_dummies(df['state'], prefix='state')\n",
    "\n",
    "# Merge the one-hot encoded states into the dataset\n",
    "monthly_features = pd.concat([monthly_features, state_dummies], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train logistic regression model\n",
    "model = LogisticRegression(class_weight='balanced', max_iter=1000)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_proba = model.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add predictions to the test set\n",
    "results = X_test.copy()\n",
    "results['actual'] = y_test\n",
    "results['predicted'] = y_pred\n",
    "\n",
    "# Plot actual vs predicted\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(results.index, results['actual'], label='Actual', marker='o')\n",
    "plt.plot(results.index, results['predicted'], label='Predicted', marker='x', linestyle='--')\n",
    "plt.title('Actual vs Predicted Disaster Occurrence')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Disaster Occurrence (1 = Yes, 0 = No)')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing the confusion matrix\n",
    "disaster_cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Converting the confusion matrix to a DataFrame for easier visualization\n",
    "cm_df = pd.DataFrame(disaster_cm, \n",
    "                     index=['Actual Negative', 'Actual Positive'], \n",
    "                     columns=['Predicted Negative', 'Predicted Positive'])\n",
    "\n",
    "# Plotting the confusion matrix\n",
    "plt.figure(figsize=(5, 4)) \n",
    "sns.heatmap(cm_df, annot=True, fmt=\"d\", cbar=False, cmap='Greens')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy score\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy}')\n",
    "\n",
    "# Precision\n",
    "precision = precision_score(y_test, y_pred)\n",
    "print(f'Precision: {precision}')\n",
    "\n",
    "# Recall (Sensitivity)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "print(f'Recall: {recall}')\n",
    "\n",
    "# F1 Score\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "print(f'F1 Score: {f1}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
