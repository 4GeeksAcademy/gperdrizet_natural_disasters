{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('../data/us_disaster_declarations.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Date Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create 'incident_dtm' column to convert 'incident_begin_date' obj to datetime\n",
    "df['incident_dtm']=pd.to_datetime(df['incident_begin_date'], format='%Y-%m-%dT%H:%M:%SZ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create 'month' column to filter month from 'incident_dtm'\n",
    "df['month']=pd.to_datetime(df['incident_dtm'], format='%b').dt.month\n",
    "\n",
    "# Create 'year' column to filter year from 'incident_dtm'\n",
    "df['year']=pd.to_datetime(df['incident_dtm'], format='%Y').dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the raw data\n",
    "df.to_parquet('../data/dtm_df.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop years before 2013\n",
    "df=df[df['year'] >= 2013]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. Clean States"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean states / remove territories \n",
    "mainland_states = [\"AL\", \"AK\", \"AZ\", \"AR\", \"CA\", \"CO\", \"CT\", \"DE\", \"FL\", \"GA\", \n",
    "                   \"HI\", \"ID\", \"IL\", \"IN\", \"IA\", \"KS\", \"KY\", \"LA\", \"ME\", \"MD\", \n",
    "                   \"MA\", \"MI\", \"MN\", \"MS\", \"MO\", \"MT\", \"NE\", \"NV\", \"NH\", \"NJ\", \n",
    "                   \"NM\", \"NY\", \"NC\", \"ND\", \"OH\", \"OK\", \"OR\", \"PA\", \"RI\", \"SC\", \n",
    "                   \"SD\", \"TN\", \"TX\", \"UT\", \"VT\", \"VA\", \"WA\", \"WV\", \"WI\", \"WY\"]\n",
    "\n",
    "df=df[df['state'].isin(mainland_states)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4. Clean Incident Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List incident types to drop\n",
    "disaster_drops=['Biological', 'Snowstorm', 'Fire', 'Severe Ice Storm', 'Tornado', 'Drought', 'Coastal Storm', \n",
    "                'Other', 'Freezing', 'Earthquake', 'Typhoon', 'Tropical Storm', 'Volcanic Eruption', 'Winter Storm',\n",
    "                'Fishing Losses', 'Mud/Landslide', 'Dam/Levee Break', 'Toxic Substances', 'Tsunami', 'Chemical', 'Human Cause', 'Terrorist']\n",
    "\n",
    "# Drop specified incident types\n",
    "for d in disaster_drops:\n",
    "    df=df[df.incident_type != d]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List incident types to combine\n",
    "common_disasters=['Severe Storm', 'Hurricane', 'Flood']\n",
    "\n",
    "# Combine specified incidents into incident type 'winter weather'\n",
    "for c in common_disasters:\n",
    "    df.loc[df['incident_type'] == c, 'incident_type'] = 'Common Disasters'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List incident types to combine\n",
    "winter_weather=['Severe Ice Storm', 'Snowstorm', 'Freezing', 'Winter Storm']\n",
    "\n",
    "# Combine specified incidents into incident type 'winter weather'\n",
    "for w in winter_weather:\n",
    "    df.loc[df['incident_type'] == w, 'incident_type'] = 'Winter Weather'\n",
    "\n",
    "#result = df[df['incident_type'] == 'Winter Weather']\n",
    "#print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5. Clean Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove unneeded columns\n",
    "\n",
    "# Create subset_df with 'incident_dtm', 'incident_type', and 'state'\n",
    "subset_df=df[['incident_dtm', 'incident_type', 'state']]\n",
    "\n",
    "subset_df.set_index('incident_dtm', inplace=True)\n",
    "\n",
    "#subset_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.6. Disaster Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode the disaster types to dummies\n",
    "disaster_dummies=pd.get_dummies(subset_df['incident_type'], dtype=int)\n",
    "\n",
    "disaster_dummies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine disaster dummies and subset_df, remove 'incident_type' column\n",
    "subset_df=pd.concat([subset_df.reset_index(drop=True), disaster_dummies.reset_index(drop=True)], axis=1)\n",
    "subset_df.drop('incident_type', axis=1, inplace=True)\n",
    "subset_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.7. Time Axis Regularization/Resampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_months(group: pd.DataFrame) -> pd.DataFrame:\n",
    "    '''Takes a yearly groupby object and sums features over months'''\n",
    "\n",
    "    group=group.resample('ME').sum()\n",
    "\n",
    "    return group\n",
    "\n",
    "def resample_months(group: pd.DataFrame) -> pd.DataFrame:\n",
    "    '''Takes working dataframe and resamples frequency to months.\n",
    "    Returns updated dataframe'''\n",
    "\n",
    "    # Set 'incident_dtm' as datetime axis\n",
    "    group=group.set_index('incident_dtm')\n",
    "\n",
    "    # Sum disasters in each month by year; removes duplicates where there was more than one disaster in a month\n",
    "    group=group.groupby(group.index.year, group_keys=False).apply(sum_months)\n",
    "\n",
    "    # Resample to monthly frequency\n",
    "    group=group.resample('D').asfreq()\n",
    "\n",
    "    # Fill missing values with 0\n",
    "    group=group.fillna(0)\n",
    "\n",
    "    # Convert everything to int\n",
    "    group=group.astype(bool)\n",
    "\n",
    "    # Reset the index, preserving the `incident_dtm`\n",
    "    group.reset_index(inplace=True, drop=False)\n",
    "\n",
    "    return group\n",
    "\n",
    "# Use resampling function on subset_df\n",
    "resampled_df=subset_df.groupby('state', group_keys=True).apply(resample_months, include_groups=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resampled_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.8. Data Reshaping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOT WORKING on resampled_df\n",
    "\n",
    "# Create 'month' column to filter month from 'incident_dtm'\n",
    "resampled_df['month']=pd.to_datetime(resampled_df['incident_dtm'], format='%b').dt.month\n",
    "\n",
    "# Create 'year' column to filter year from 'incident_dtm'\n",
    "resampled_df['year']=pd.to_datetime(resampled_df['incident_dtm'], format='%Y').dt.year\n",
    "\n",
    "reshaped_df=resampled_df.set_index(['year', 'state', 'month'], inplace=True)\n",
    "\n",
    "reshaped_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df=subset_df\n",
    "\n",
    "# Create 'month' column to filter month from 'incident_dtm'\n",
    "test_df['month']=pd.to_datetime(test_df['incident_dtm'], format='%b').dt.month\n",
    "\n",
    "# Create 'year' column to filter year from 'incident_dtm'\n",
    "test_df['year']=pd.to_datetime(test_df['incident_dtm'], format='%Y').dt.year\n",
    "\n",
    "# Set 'year', 'state', and 'month' indices\n",
    "test_df.set_index(['year', 'state', 'month'], inplace=True)\n",
    "\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create 'month' column to filter month from 'incident_dtm'\n",
    "subset_df['month']=pd.to_datetime(subset_df['incident_dtm'], format='%b').dt.month\n",
    "\n",
    "# Create 'year' column to filter year from 'incident_dtm'\n",
    "subset_df['year']=pd.to_datetime(subset_df['incident_dtm'], format='%Y').dt.year\n",
    "\n",
    "# Set 'year', 'state', and 'month' indices\n",
    "subset_df.set_index(['year', 'state', 'month'], inplace=True)\n",
    "\n",
    "subset_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
