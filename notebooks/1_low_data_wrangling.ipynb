{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('../data/us_disaster_declarations.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Date Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create 'incident_dtm' column to convert 'incident_begin_date' obj to datetime\n",
    "df['incident_dtm']=pd.to_datetime(df['incident_begin_date'], format='%Y-%m-%dT%H:%M:%SZ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create 'month' column to filter month from 'incident_dtm'\n",
    "df['month']=pd.to_datetime(df['incident_dtm'], format='%b').dt.month\n",
    "\n",
    "# Create 'year' column to filter year from 'incident_dtm'\n",
    "df['year']=pd.to_datetime(df['incident_dtm'], format='%Y').dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the raw data\n",
    "# Original df plus: incident_dtm / year / month\n",
    "df.to_parquet('../data/dtm_df.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop years before YYYY\n",
    "df=df[df['year'] >= 2009]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. Clean States"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean states / remove territories \n",
    "mainland_states = [\"AL\", \"AK\", \"AZ\", \"AR\", \"CA\", \"CO\", \"CT\", \"DE\", \"FL\", \"GA\", \n",
    "                   \"HI\", \"ID\", \"IL\", \"IN\", \"IA\", \"KS\", \"KY\", \"LA\", \"ME\", \"MD\", \n",
    "                   \"MA\", \"MI\", \"MN\", \"MS\", \"MO\", \"MT\", \"NE\", \"NV\", \"NH\", \"NJ\", \n",
    "                   \"NM\", \"NY\", \"NC\", \"ND\", \"OH\", \"OK\", \"OR\", \"PA\", \"RI\", \"SC\", \n",
    "                   \"SD\", \"TN\", \"TX\", \"UT\", \"VT\", \"VA\", \"WA\", \"WV\", \"WI\", \"WY\"]\n",
    "\n",
    "df=df[df['state'].isin(mainland_states)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4. Clean Incident Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List incident types to drop\n",
    "disaster_drops=['Biological', 'Snowstorm', 'Fire', 'Severe Ice Storm', 'Tornado', 'Drought', 'Coastal Storm', \n",
    "                'Other', 'Freezing', 'Earthquake', 'Typhoon', 'Tropical Storm', 'Volcanic Eruption', 'Winter Storm',\n",
    "                'Fishing Losses', 'Mud/Landslide', 'Dam/Levee Break', 'Toxic Substances', 'Tsunami', 'Chemical', 'Human Cause', 'Terrorist']\n",
    "\n",
    "# Drop specified incident types\n",
    "for d in disaster_drops:\n",
    "    df=df[df.incident_type != d]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List incident types to combine\n",
    "common_disasters=['Severe Storm', 'Hurricane', 'Flood']\n",
    "\n",
    "# Combine specified incidents into incident type 'winter weather'\n",
    "for c in common_disasters:\n",
    "    df.loc[df['incident_type'] == c, 'incident_type'] = 'Common Disasters'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List incident types to combine\n",
    "winter_weather=['Severe Ice Storm', 'Snowstorm', 'Freezing', 'Winter Storm']\n",
    "\n",
    "# Combine specified incidents into incident type 'winter weather'\n",
    "for w in winter_weather:\n",
    "    df.loc[df['incident_type'] == w, 'incident_type'] = 'Winter Weather'\n",
    "\n",
    "#result = df[df['incident_type'] == 'Winter Weather']\n",
    "#print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5. Clean Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>incident_dtm</th>\n",
       "      <th>incident_type</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1953-05-02</td>\n",
       "      <td>Tornado</td>\n",
       "      <td>GA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1953-05-15</td>\n",
       "      <td>Tornado</td>\n",
       "      <td>TX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1953-05-29</td>\n",
       "      <td>Flood</td>\n",
       "      <td>LA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1953-06-02</td>\n",
       "      <td>Tornado</td>\n",
       "      <td>MI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1953-06-06</td>\n",
       "      <td>Flood</td>\n",
       "      <td>MT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64087</th>\n",
       "      <td>2022-12-23</td>\n",
       "      <td>Severe Storm</td>\n",
       "      <td>ME</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64088</th>\n",
       "      <td>2023-03-24</td>\n",
       "      <td>Severe Storm</td>\n",
       "      <td>MS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64089</th>\n",
       "      <td>2023-03-24</td>\n",
       "      <td>Severe Storm</td>\n",
       "      <td>MS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64090</th>\n",
       "      <td>2023-03-24</td>\n",
       "      <td>Severe Storm</td>\n",
       "      <td>MS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64091</th>\n",
       "      <td>2023-03-24</td>\n",
       "      <td>Severe Storm</td>\n",
       "      <td>MS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>61759 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      incident_dtm incident_type state\n",
       "0       1953-05-02       Tornado    GA\n",
       "1       1953-05-15       Tornado    TX\n",
       "2       1953-05-29         Flood    LA\n",
       "3       1953-06-02       Tornado    MI\n",
       "4       1953-06-06         Flood    MT\n",
       "...            ...           ...   ...\n",
       "64087   2022-12-23  Severe Storm    ME\n",
       "64088   2023-03-24  Severe Storm    MS\n",
       "64089   2023-03-24  Severe Storm    MS\n",
       "64090   2023-03-24  Severe Storm    MS\n",
       "64091   2023-03-24  Severe Storm    MS\n",
       "\n",
       "[61759 rows x 3 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove unneeded columns\n",
    "\n",
    "# Create subset_df with 'incident_dtm', 'incident_type', and 'state'\n",
    "subset_df=df[['incident_dtm', 'incident_type', 'state']]\n",
    "\n",
    "#subset_df.set_index('incident_dtm', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the raw data\n",
    "# Subset df: incident_dtm / incident_type / state\n",
    "subset_df.to_parquet('../data/subset_df.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.6. Monthly Aggregation and 'No Disaster' Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_30969/1069632258.py:2: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  monthly_disasters=subset_df.resample('M').size()\n"
     ]
    }
   ],
   "source": [
    "# Monthly aggregation and \"no disaster\" feature\n",
    "monthly_disasters=subset_df.resample('M').size()\n",
    "monthly_disasters_df=monthly_disasters.to_frame(name='disaster_count')\n",
    "monthly_disasters_df['disaster?']=monthly_disasters_df['disaster_count'].apply(lambda x: 0 if x == 0 else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the raw data\n",
    "# Subset df: incident_dtm (index) / disaster_count / disaster?\n",
    "monthly_disasters_df.to_parquet('../data/clean_state_type_df.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the raw data\n",
    "# Subset df (2009-2023): incident_dtm (index) / disaster_count / disaster?\n",
    "monthly_disasters_df.to_parquet('../data/clean_state_type_09_df.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.7. Disaster Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode the disaster types to dummies\n",
    "disaster_dummies=pd.get_dummies(subset_df['incident_type'], dtype=int)\n",
    "\n",
    "disaster_dummies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine disaster dummies and subset_df, remove 'incident_type' column\n",
    "subset_df=pd.concat([subset_df.reset_index(drop=True), disaster_dummies.reset_index(drop=True)], axis=1)\n",
    "subset_df.drop('incident_type', axis=1, inplace=True)\n",
    "subset_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.8. Time Axis Regularization/Resampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_months(group: pd.DataFrame) -> pd.DataFrame:\n",
    "    '''Takes a yearly groupby object and sums features over months'''\n",
    "\n",
    "    group=group.resample('ME').sum()\n",
    "\n",
    "    return group\n",
    "\n",
    "def resample_months(group: pd.DataFrame) -> pd.DataFrame:\n",
    "    '''Takes working dataframe and resamples frequency to months.\n",
    "    Returns updated dataframe'''\n",
    "\n",
    "    # Set 'incident_dtm' as datetime axis\n",
    "    group=group.set_index('incident_dtm')\n",
    "\n",
    "    # Sum disasters in each month by year; removes duplicates where there was more than one disaster in a month\n",
    "    group=group.groupby(group.index.year, group_keys=False).apply(sum_months)\n",
    "\n",
    "    # Resample to monthly frequency\n",
    "    group=group.resample('D').asfreq()\n",
    "\n",
    "    # Fill missing values with 0\n",
    "    group=group.fillna(0)\n",
    "\n",
    "    # Convert everything to int\n",
    "    group=group.astype(bool)\n",
    "\n",
    "    # Reset the index, preserving the `incident_dtm`\n",
    "    group.reset_index(inplace=True, drop=False)\n",
    "\n",
    "    return group\n",
    "\n",
    "# Use resampling function on subset_df\n",
    "resampled_df=subset_df.groupby('state', group_keys=True).apply(resample_months, include_groups=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resampled_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.9. Data Reshaping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOT WORKING on resampled_df\n",
    "\n",
    "# Create 'month' column to filter month from 'incident_dtm'\n",
    "resampled_df['month']=pd.to_datetime(resampled_df['incident_dtm'], format='%b').dt.month\n",
    "\n",
    "# Create 'year' column to filter year from 'incident_dtm'\n",
    "resampled_df['year']=pd.to_datetime(resampled_df['incident_dtm'], format='%Y').dt.year\n",
    "\n",
    "reshaped_df=resampled_df.set_index(['year', 'state', 'month'], inplace=True)\n",
    "\n",
    "reshaped_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df=subset_df\n",
    "\n",
    "# Create 'month' column to filter month from 'incident_dtm'\n",
    "test_df['month']=pd.to_datetime(test_df['incident_dtm'], format='%b').dt.month\n",
    "\n",
    "# Create 'year' column to filter year from 'incident_dtm'\n",
    "test_df['year']=pd.to_datetime(test_df['incident_dtm'], format='%Y').dt.year\n",
    "\n",
    "# Set 'year', 'state', and 'month' indices\n",
    "test_df.set_index(['year', 'state', 'month'], inplace=True)\n",
    "\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create 'month' column to filter month from 'incident_dtm'\n",
    "subset_df['month']=pd.to_datetime(subset_df['incident_dtm'], format='%b').dt.month\n",
    "\n",
    "# Create 'year' column to filter year from 'incident_dtm'\n",
    "subset_df['year']=pd.to_datetime(subset_df['incident_dtm'], format='%Y').dt.year\n",
    "\n",
    "# Set 'year', 'state', and 'month' indices\n",
    "subset_df.set_index(['year', 'state', 'month'], inplace=True)\n",
    "\n",
    "subset_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.0. Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove non-weather disasters (include earthquakes, volcanic eruptions)\n",
    "# Combine severe ice storm, snowstorm, freezing, and winter storm into 'winter weather'\n",
    "\n",
    "# Drop some disaster types - focus on weather-related disasters (include wildfires, earthquakes, and volcanic eruptions)\n",
    "disaster_drops=['Biological', 'Chemical', 'Fishing Losses', 'Human Cause', 'Other', 'Terrorist', 'Toxic Substances']\n",
    "resampled_df.drop(disaster_drops, axis=1, inplace=True)\n",
    "\n",
    "# Combine winter-related weather disasters\n",
    "resampled_df['Winter weather']=resampled_df['Severe Ice Storm'] + resampled_df['Snowstorm'] + resampled_df['Freezing'] + resampled_df['Winter Storm']\n",
    "resampled_df.drop(['Severe Ice Storm','Snowstorm','Freezing','Winter Storm'], axis=1, inplace=True)\n",
    "resampled_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up the index\n",
    "resampled_df.reset_index(inplace=True)\n",
    "resampled_df.drop('level_1', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract month and year from 'declaration_dtm' and drop dtm column\n",
    "resampled_df['year']=resampled_df['declaration_dtm'].dt.year\n",
    "resampled_df['month']=resampled_df['declaration_dtm'].dt.month\n",
    "resampled_df.drop('declaration_dtm', axis=1, inplace=True)\n",
    "resampled_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
